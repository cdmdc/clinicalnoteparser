2025-11-24 15:50:19 - app.pipeline - INFO - Logging configured: file=/Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/19/pipeline.log, level=DEBUG
2025-11-24 15:50:19 - app.pipeline - INFO - Processing document: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/data/archive/mtsamples_pdf/mtsamples_pdf/19.pdf
2025-11-24 15:50:19 - app.pipeline - INFO - Output directory: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/19
2025-11-24 15:50:19 - app.pipeline - INFO - Configuration: model=qwen2.5:7b, temperature=0.1
2025-11-24 15:50:19 - app.pipeline - INFO - Execution mode: toc_only=False, summary_only=False, plan_only=False, no_evaluation=False
2025-11-24 15:50:19 - app.pipeline - INFO - [STEP 1] Ingesting document: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/data/archive/mtsamples_pdf/mtsamples_pdf/19.pdf
2025-11-24 15:50:19 - app.ingestion - INFO - Loading PDF: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/data/archive/mtsamples_pdf/mtsamples_pdf/19.pdf
2025-11-24 15:50:19 - app.ingestion - INFO - Ingested document: 2281 characters, 1 pages, note_id: 19
2025-11-24 15:50:19 - app.pipeline - INFO - ✓ Ingested: 2281 chars, 1 pages, note_id: 19
2025-11-24 15:50:19 - app.pipeline - INFO - Saved canonical text to: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/19/canonical_text.txt
2025-11-24 15:50:19 - app.pipeline - INFO - [STEP 2/6] Detecting sections...
2025-11-24 15:50:19 - app.sections - INFO - Overview section detected: end=259, title=Overview
2025-11-24 15:50:19 - app.sections - INFO - Found 9 section headers (after empty lines, all-caps): ['ADMISSION DIAGNOSIS', 'DISCHARGE DIAGNOSIS', 'PROCEDURE', 'SERVICE', 'CONSULT', 'HISTORY OF PRESENT ILLNESS', 'HOSPITAL COURSE', 'DISCHARGE INSTRUCTIONS', 'DISCHARGE MEDICATIONS']
2025-11-24 15:50:19 - app.sections - INFO - Found 9 potential section headers
2025-11-24 15:50:19 - app.sections - INFO - Detected 10 sections: ['Overview', 'ADMISSION DIAGNOSIS', 'DISCHARGE DIAGNOSIS', 'PROCEDURE', 'SERVICE', 'CONSULT', 'HISTORY OF PRESENT ILLNESS', 'HOSPITAL COURSE', 'DISCHARGE INSTRUCTIONS', 'DISCHARGE MEDICATIONS']
2025-11-24 15:50:19 - app.pipeline - INFO - ✓ Detected 10 sections
2025-11-24 15:50:19 - app.pipeline - INFO -   1. Overview (pages 1-1, chars 0-259)
2025-11-24 15:50:19 - app.pipeline - INFO -   2. ADMISSION DIAGNOSIS (pages 1-1, chars 259-308)
2025-11-24 15:50:19 - app.pipeline - INFO -   3. DISCHARGE DIAGNOSIS (pages 1-1, chars 308-357)
2025-11-24 15:50:19 - app.pipeline - INFO -   4. PROCEDURE (pages 1-1, chars 357-398)
2025-11-24 15:50:19 - app.pipeline - INFO -   5. SERVICE (pages 1-1, chars 398-417)
2025-11-24 15:50:19 - app.pipeline - INFO -   6. CONSULT (pages 1-1, chars 417-448)
2025-11-24 15:50:19 - app.pipeline - INFO -   7. HISTORY OF PRESENT ILLNESS (pages 1-1, chars 448-775)
2025-11-24 15:50:19 - app.pipeline - INFO -   8. HOSPITAL COURSE (pages 1-1, chars 775-1411)
2025-11-24 15:50:19 - app.pipeline - INFO -   9. DISCHARGE INSTRUCTIONS (pages 1-1, chars 1411-2183)
2025-11-24 15:50:19 - app.pipeline - INFO -   10. DISCHARGE MEDICATIONS (pages 1-1, chars 2183-2281)
2025-11-24 15:50:19 - app.sections - INFO - Saved ToC to /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/19/toc.json with 10 sections
2025-11-24 15:50:19 - app.pipeline - INFO - ✓ Saved ToC to: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/19/toc.json
2025-11-24 15:50:19 - app.pipeline - INFO - [STEP 3/6] Creating chunks...
2025-11-24 15:50:19 - app.chunks - INFO - Created 10 chunks from 10 sections
2025-11-24 15:50:19 - app.pipeline - INFO - ✓ Created 10 chunks
2025-11-24 15:50:19 - app.chunks - INFO - Saved 10 chunks to /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/19/chunks.json
2025-11-24 15:50:19 - app.pipeline - INFO - ✓ Saved chunks to: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/19/chunks.json
2025-11-24 15:50:19 - app.pipeline - INFO - Initializing LLM client...
2025-11-24 15:50:19 - app.llm - INFO - ✓ Apple Silicon detected - MPS environment variables set for Ollama
2025-11-24 15:50:19 - app.llm - DEBUG - Note: Install PyTorch for MPS availability verification
2025-11-24 15:50:19 - app.llm - INFO - LLM client configured for GPU acceleration (MPS)
2025-11-24 15:50:19 - app.llm - INFO - Initialized LLM client with model: qwen2.5:7b, temperature: 0.1
2025-11-24 15:50:19 - app.pipeline - INFO - ✓ LLM client initialized (model: qwen2.5:7b)
2025-11-24 15:50:19 - app.pipeline - INFO - [STEP 4/6] Generating summary...
2025-11-24 15:50:19 - app.pipeline - INFO -   Processing 10 chunks at once...
2025-11-24 15:50:19 - app.summarizer - INFO - Calling LLM (model: qwen2.5:7b, temperature: 0.1)
2025-11-24 15:50:19 - app.summarizer - DEBUG - Prompt preview: # Text Summary Prompt

## SYSTEM ROLE

You are a medical documentation extraction assistant.

Your job is to extract only information that is explicitly present in the provided chunks of a clinical no...
2025-11-24 15:50:19 - httpcore.connection - DEBUG - connect_tcp.started host='localhost' port=11434 local_address=None timeout=None socket_options=None
2025-11-24 15:50:19 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10fa27e10>
2025-11-24 15:50:19 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-11-24 15:50:19 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-11-24 15:50:19 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-11-24 15:50:19 - httpcore.http11 - DEBUG - send_request_body.complete
2025-11-24 15:50:19 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-11-24 15:50:29 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/x-ndjson'), (b'Date', b'Mon, 24 Nov 2025 20:50:29 GMT'), (b'Transfer-Encoding', b'chunked')])
2025-11-24 15:50:29 - httpx - INFO - HTTP Request: POST http://localhost:11434/api/chat "HTTP/1.1 200 OK"
2025-11-24 15:50:29 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-11-24 15:50:33 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-11-24 15:50:33 - httpcore.http11 - DEBUG - response_closed.started
2025-11-24 15:50:33 - httpcore.http11 - DEBUG - response_closed.complete
2025-11-24 15:50:33 - app.planner - DEBUG - LLM response (attempt 1): ```json
{
  "recommendations": [
    {
      "number": 1,
      "recommendation": "laparoscopic Roux-en-Y gastric bypass",
      "source": "[OVERVIEW] section, chunk_0:22-43",
      "confidence": 1.0,
      "hallucination_guard_note": null
    }
  ]
}
```...
2025-11-24 15:50:33 - app.planner - INFO - LLM call succeeded (attempt 1, 42.28s)
2025-11-24 15:50:33 - app.planner - DEBUG - Parsed JSON: {
  "recommendations": [
    {
      "number": 1,
      "recommendation": "laparoscopic Roux-en-Y gastric bypass",
      "source": "[OVERVIEW] section, chunk_0:22-43",
      "confidence": 1.0,
      "hallucination_guard_note": null
    }
  ]
}...
2025-11-24 15:50:33 - app.pipeline - INFO - ✓ Generated structured plan with 1 prioritized recommendations
2025-11-24 15:50:33 - app.planner - INFO - Saved structured plan to /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/18/plan.json
2025-11-24 15:50:33 - app.pipeline - INFO - ✓ Saved plan to: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/18/plan.json
2025-11-24 15:50:33 - app.pipeline - INFO - [STEP 6/6] Evaluating results...
2025-11-24 15:50:33 - app.evaluation - INFO - Evaluating semantic accuracy of plan recommendations using Ollama embeddings...
2025-11-24 15:50:33 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:11434
2025-11-24 15:50:34 - urllib3.connectionpool - DEBUG - http://127.0.0.1:11434 "POST /api/embeddings HTTP/1.1" 200 None
2025-11-24 15:50:34 - urllib3.connectionpool - DEBUG - Starting new HTTP connection (1): 127.0.0.1:11434
2025-11-24 15:50:34 - urllib3.connectionpool - DEBUG - http://127.0.0.1:11434 "POST /api/embeddings HTTP/1.1" 200 None
2025-11-24 15:50:34 - app.evaluation - INFO - Saved evaluation report to /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/18/evaluation.json
2025-11-24 15:50:34 - app.pipeline - INFO - ✓ Saved evaluation to: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/18/evaluation.json
2025-11-24 15:50:34 - app.pipeline - INFO - 
[EVALUATION METRICS]
2025-11-24 15:50:34 - app.pipeline - INFO - Citation Coverage:
2025-11-24 15:50:34 - app.pipeline - INFO -   Summary: 100.0% (32/32)
2025-11-24 15:50:34 - app.pipeline - INFO -   Plan: 100.0% (1/1)
2025-11-24 15:50:34 - app.pipeline - INFO -   Overall: 100.0%
2025-11-24 15:50:34 - app.pipeline - INFO - 
Citation Validity: 100.0% (33/33)
2025-11-24 15:50:34 - app.pipeline - INFO - 
Hallucination Rate: 0.0% (0/33 orphan claims)
2025-11-24 15:50:34 - app.pipeline - INFO - 
Citation Overlap Jaccard: 0.0019 (avg, 528 pairs, range: 0.0000-1.0000)
2025-11-24 15:50:34 - app.pipeline - INFO - 
Span Consistency: 100.0% (33/33)
2025-11-24 15:50:34 - app.pipeline - INFO - 
Summary Statistics:
2025-11-24 15:50:34 - app.pipeline - INFO -   Total facts: 32
2025-11-24 15:50:34 - app.pipeline - INFO -   Total recommendations: 1
2025-11-24 15:50:34 - app.pipeline - INFO -   Average confidence: 1.00
2025-11-24 15:50:34 - app.pipeline - INFO - 
✓ Pipeline completed successfully!
2025-11-24 15:50:34 - app.pipeline - INFO - Output directory: /Users/davidavinci/Documents/GitHub/clinicalnoteparser/results/18
2025-11-24 15:50:34 - app.pipeline - INFO -   - canonical_text.txt
2025-11-24 15:50:34 - app.pipeline - INFO -   - toc.json
2025-11-24 15:50:34 - app.pipeline - INFO -   - chunks.json
2025-11-24 15:50:34 - app.pipeline - INFO -   - summary.json
2025-11-24 15:50:34 - app.pipeline - INFO -   - plan.json
2025-11-24 15:50:34 - app.pipeline - INFO -   - evaluation.json
2025-11-24 15:50:34 - app.pipeline - INFO -   - pipeline.log
2025-11-24 15:50:34 - root - INFO - [19/21] ✓ 18.pdf
2025-11-24 15:50:34 - app.pipeline - INFO - Checking Ollama availability...
2025-11-24 15:50:34 - app.pipeline - INFO - ✓ Ollama is available
